# Homework 15 Kafka

### Concepts:
1. Topic: A topic in Kafka is a logical channel to which producers publish messages and from which consumers read messages. Topics are split into partitions to allow for parallelism.

2. Partition: A partition is a segment of a topic that Kafka uses to parallelize data handling. Each partition is an ordered, immutable sequence of records.

3. Broker: A broker in Kafka is a server that handles read and write requests to the partitions and topics. It stores the data and serves it to consumers when requested.

4. Consumer group: A consumer group is a group of consumers that work together to consume records from topics. Each partition of the topic is consumed by only one consumer in the group, providing load balancing.

5. Producer: A producer in Kafka is an application that sends records (messages) to a Kafka topic.

6. Offset: The offset is the position of a message within a partition. Consumers keep track of the offset to know which messages have been consumed.

7. Zookeeper: Zookeeper is a centralized service used by Kafka for coordinating distributed systems. Kafka uses it for leader election, cluster management, and maintaining consumer offsets.

### Questions:
### 1. Given N (number of partitions) and M (number of consumers,) what will happen when N>=M and N<M respectively?

 - When N >= M: Each consumer in the group will consume at least one partition, and some consumers may consume more than one partition.
 - When N < M: Some consumers will remain idle, as each partition can only be consumed by one consumer in a consumer group at a time.

### 2. Explain how brokers work with topics?

 - Brokers manage topic data. Each topic is split into partitions, and each broker stores partitions. When a producer sends data, it goes to the leader of a partition on a broker. Other brokers replicate the data for fault tolerance.

### 3. Are messages pushed to consumers or consumers pull messages from topics?

 - Consumers pull messages from topics. They request messages from Kafka brokers by fetching data from the partitions assigned to them.

### 4. How to avoid duplicate consumption of messages?

 - Duplicate consumption can be avoided by tracking offsets. By committing offsets after message processing, Kafka ensures that each message is consumed exactly once. Kafka's "exactly-once" processing feature can also help ensure this behavior.

### 5. What will happen if some consumers are down in a consumer group? Will data loss occur? Why?

 - If some consumers are down, the remaining consumers in the group will rebalance and take over the partitions of the failed consumers. No data loss occurs because Kafka stores the messages and allows another consumer to pick up from where the failed one left off.

### 6. What will happen if an entire consumer group is down? Will data loss occur? Why?

 - If the entire consumer group is down, there will be no active consumers to read the data, but no data will be lost. Kafka retains the messages until the retention period expires, allowing the consumer group to start up later and consume from where it left off.

### 7. Explain consumer lag and how to resolve it?

 - Consumer lag is the difference between the last committed offset by the consumer and the last produced offset on the broker. It can be resolved by ensuring consumers are processing messages fast enough, scaling the number of consumers, or optimizing consumer processing.

### 8. Explain how Kafka tracks message delivery?

 - Kafka tracks message delivery through consumer offsets. Each consumer commits its offset, telling Kafka which messages have been consumed. This helps Kafka manage which records have been processed and ensures that consumers do not reprocess messages unless necessary.

### 9. Compare Kafka vs RabbitMQ, compare messaging frameworks vs MySQL (Why Kafka)?

 - Kafka vs RabbitMQ: Kafka is designed for high throughput, horizontal scaling, and is optimized for real-time stream processing, whereas RabbitMQ focuses on message delivery guarantees and complex routing. RabbitMQ is more suited for smaller message sizes and immediate message consumption.

 - Messaging Frameworks vs MySQL: Kafka, being a distributed event streaming platform, is better for real-time processing and high throughput compared to MySQL, which is optimized for transactions and relational database tasks. Kafka allows for decoupled systems where different services can subscribe to real-time data streams, while MySQL is mainly used for query-driven data retrieval.



### Still working on coding part

