- Topic: In Kafka, a topic is a category or stream of records to which messages are published. Producers write messages to topics, and consumers read messages from topics.

- Partition: Each Kafka topic is divided into partitions, which are ordered and immutable sequences of records. Each record in a partition has an offset, which is a unique identifier within that partition.

- Broker: A broker is a Kafka server responsible for receiving and storing records. Brokers work together in a Kafka cluster, and each partition of a topic is replicated across multiple brokers for fault tolerance.

- Consumer Group: A consumer group is a group of consumers that work together to consume messages from topics. Each message in a partition is consumed by only one consumer in a consumer group.

- Producer: Producers are clients that publish (produce) messages to Kafka topics.

- Offset: The offset is a unique identifier for a message within a partition. It helps Kafka maintain the order of messages and track which messages have been consumed.

- Zookeeper: Zookeeper is used by Kafka to manage brokers, maintain metadata about topics, and keep track of offsets for consumers. It's a centralized service for maintaining configuration information and providing distributed synchronization.

## Given N (number of partitions) and M (number of consumers,) what will happen when N>=M and N<M respectively?
- N >= M: Each consumer will be assigned at least one partition. Some consumers may have more than one partition to consume.
- N < M: Some consumers will be idle because there are fewer partitions than consumers. Kafka assigns one consumer per partition, so the excess consumers will not have any partitions to consume.

## Explain how brokers work with topics?
Brokers store and manage data for Kafka topics. A topic is divided into partitions, and those partitions are distributed across multiple brokers. Brokers communicate with each other to maintain consistency and data replication across partitions. When a producer sends a message to a topic, the broker that hosts the partition will store the message.

## Are messages pushed to consumers or consumers pull messages from topics?
Consumers pull messages from topics. Consumers decide when to fetch new data by polling the Kafka broker, giving them control over the rate of consumption.

## How to avoid duplicate consumption of messages?
To avoid duplicate consumption, you can enable idempotent producers in Kafka, ensuring that the same message is not produced multiple times. Additionally, Kafka consumers can commit offsets after processing messages, ensuring that only messages after the committed offset are consumed again.

## What will happen if some consumers are down in a consumer group? Will data loss occur? Why?
If some consumers in a consumer group go down, Kafka will rebalance the partitions across the remaining consumers, ensuring that the data is still consumed. No data loss will occur because messages remain in the partitions until they are consumed and acknowledged.

## What happens if an entire consumer group is down?
If an entire consumer group is down, no data loss occurs because the messages remain in Kafka’s partitions. The messages will remain available for consumption when the consumer group becomes available again.

## Explain consumer lag and how to resolve it?
Consumer lag refers to the difference between the latest message written to a partition and the last message consumed. It occurs when the consumer is not processing messages as quickly as they are being produced. You can resolve consumer lag by scaling up the number of consumers or optimizing the consumer’s processing logic.

## How does Kafka track message delivery?
Kafka tracks message delivery using offsets. Each consumer tracks the last offset of the messages it has consumed, and these offsets are committed to Kafka to ensure the consumer can pick up from where it left off in case of failure.

## Kafka vs RabbitMQ, Kafka vs MySQL
Kafka vs RabbitMQ: Kafka is designed for distributed streaming and log management, making it ideal for handling large volumes of data with high throughput and fault tolerance. RabbitMQ is optimized for message routing with different patterns such as fanout, direct, and topic exchanges.
Kafka vs MySQL: Kafka is designed for event-driven architectures and streaming, whereas MySQL is a relational database primarily used for structured data storage. Kafka is preferred when you need to process real-time data streams and handle large data volumes.



# Still need time to do this.